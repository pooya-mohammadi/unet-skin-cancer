{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEWth_se0FeA"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldCynGyVy-7t",
        "outputId": "354bbdc1-a6c8-40cc-f374-158f29d75f0b"
      },
      "source": [
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_Data.zip   #Download Train zip file\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_GroundTruth.zip #Download Mask_train zip file\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_Data.zip       #Download Test zip file\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_GroundTruth.zip    #Download Mask_test zip file"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-18 10:29:00--  https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_Data.zip\n",
            "Resolving isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)... 52.217.203.41\n",
            "Connecting to isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)|52.217.203.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 631625308 (602M) [application/zip]\n",
            "Saving to: ‘ISBI2016_ISIC_Part1_Training_Data.zip’\n",
            "\n",
            "ISBI2016_ISIC_Part1 100%[===================>] 602.36M  15.8MB/s    in 40s     \n",
            "\n",
            "2021-09-18 10:29:41 (15.1 MB/s) - ‘ISBI2016_ISIC_Part1_Training_Data.zip’ saved [631625308/631625308]\n",
            "\n",
            "--2021-09-18 10:29:41--  https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_GroundTruth.zip\n",
            "Resolving isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)... 52.216.145.19\n",
            "Connecting to isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)|52.216.145.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6000606 (5.7M) [application/zip]\n",
            "Saving to: ‘ISBI2016_ISIC_Part1_Training_GroundTruth.zip’\n",
            "\n",
            "ISBI2016_ISIC_Part1 100%[===================>]   5.72M  3.86MB/s    in 1.5s    \n",
            "\n",
            "2021-09-18 10:29:43 (3.86 MB/s) - ‘ISBI2016_ISIC_Part1_Training_GroundTruth.zip’ saved [6000606/6000606]\n",
            "\n",
            "--2021-09-18 10:29:43--  https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_Data.zip\n",
            "Resolving isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)... 52.216.77.236\n",
            "Connecting to isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)|52.216.77.236|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 242932767 (232M) [application/zip]\n",
            "Saving to: ‘ISBI2016_ISIC_Part1_Test_Data.zip’\n",
            "\n",
            "ISBI2016_ISIC_Part1 100%[===================>] 231.68M  16.0MB/s    in 17s     \n",
            "\n",
            "2021-09-18 10:30:01 (13.7 MB/s) - ‘ISBI2016_ISIC_Part1_Test_Data.zip’ saved [242932767/242932767]\n",
            "\n",
            "--2021-09-18 10:30:01--  https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_GroundTruth.zip\n",
            "Resolving isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)... 52.217.193.129\n",
            "Connecting to isic-challenge-data.s3.amazonaws.com (isic-challenge-data.s3.amazonaws.com)|52.217.193.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2376407 (2.3M) [application/zip]\n",
            "Saving to: ‘ISBI2016_ISIC_Part1_Test_GroundTruth.zip’\n",
            "\n",
            "ISBI2016_ISIC_Part1 100%[===================>]   2.27M  1.75MB/s    in 1.3s    \n",
            "\n",
            "2021-09-18 10:30:03 (1.75 MB/s) - ‘ISBI2016_ISIC_Part1_Test_GroundTruth.zip’ saved [2376407/2376407]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmVbpQnSWT5i"
      },
      "source": [
        "#Now unzip 4 above files\n",
        "!unzip -q ISBI2016_ISIC_Part1_Training_Data.zip\n",
        "!unzip -q ISBI2016_ISIC_Part1_Training_GroundTruth.zip\n",
        "!unzip -q ISBI2016_ISIC_Part1_Test_Data.zip\n",
        "!unzip -q ISBI2016_ISIC_Part1_Test_GroundTruth.zip"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEXr6BTIlozg"
      },
      "source": [
        "# Data arrangment\n",
        "\n",
        "\n",
        "Arrange_data function Sort image paths and return input images and mask images in list.\n",
        "\n",
        "**Note** : size of images are so big, and because of that my RAM was crashed.so The photos resize one tenth of the original size. Now pictures are in (256,256), a size that gives us advantages when working with U-Net\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqtSxuEMWUCw"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.image as mpimg\n",
        "# import os\n",
        "# from os.path import dirname, join as pjoin\n",
        "# import cv2\n",
        "\n",
        "# def arrange_data(input_dir, mask_dir):\n",
        "#     input_img_paths = sorted(\n",
        "#         [\n",
        "#             os.path.join(input_dir, fname)\n",
        "#             for fname in os.listdir(input_dir)\n",
        "#             if fname.endswith(\".jpg\")\n",
        "#         ]\n",
        "#     )\n",
        "#     input_array_list = [cv2.resize(mpimg.imread(str_index), (256,256))\n",
        "#                   for str_index in input_img_paths]\n",
        "\n",
        "#     mask_img_paths = sorted(\n",
        "#         [\n",
        "#             os.path.join(mask_dir, fname)\n",
        "#             for fname in os.listdir(mask_dir)\n",
        "#             if fname.endswith(\".png\")\n",
        "#         ]\n",
        "#     )\n",
        "#     mask_array_list = [cv2.resize(mpimg.imread(str_index), (256,256))\n",
        "#                        for str_index in mask_img_paths]\n",
        "#     return input_array_list, mask_array_list\n",
        "\n",
        "# #Train images and mask of them save in 2 below var\n",
        "# X_train_list, Y_train_list = arrange_data(\"/content/ISBI2016_ISIC_Part1_Training_Data\",\n",
        "#              \"/content/ISBI2016_ISIC_Part1_Training_GroundTruth\")\n",
        "\n",
        "# #Test images and mask of them save in 2 below var\n",
        "# X_test_list, Y_test_list = arrange_data(\"/content/ISBI2016_ISIC_Part1_Test_Data\",\n",
        "#              \"/content/ISBI2016_ISIC_Part1_Test_GroundTruth\")\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ds3jVjSKkjP"
      },
      "source": [
        "import urllib.request as urllib\n",
        "import zipfile\n",
        "\n",
        "# def preprocessing(\"https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_Data.zip\",\n",
        "#                   https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_GroundTruth.zip,\n",
        "#                   https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_Data.zip,\n",
        "#                   https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_GroundTruth.zip):\n",
        "    \n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1i0_jbMh-rT"
      },
      "source": [
        "#from io import BytesIO\n",
        "#from urllib.request import urlopen\n",
        "# from zipfile import ZipFile\n",
        "\n",
        "# def preprocessing(train_zip, test_zip, mask_train_zip, mask_test_zip,\n",
        "#                  train_path, test_path, mask_train_path,mask_test_path):\n",
        "    \n",
        "#     with urlopen(train_zip) as zip_train:\n",
        "#         with ZipFile(BytesIO(zip_train.read())) as zfile:\n",
        "#             zfile.extractall(train_path)\n",
        "#     with urlopen(test_zip) as zip_test:\n",
        "#         with ZipFile(BytesIO(zip_test.read())) as zfile:\n",
        "#             zfile.extractall(test_path)\n",
        "#     with urlopen(mask_train_zip) as zip_mask_train:\n",
        "#         with ZipFile(BytesIO(zip_mask_train.read())) as zfile:\n",
        "#             zfile.extractall(mask_train_path)\n",
        "#     with urlopen(mask_test_zip) as zip_mask_test:\n",
        "#         with ZipFile(BytesIO(zip_mask_test.read())) as zfile:\n",
        "#             zfile.extractall(mask_test_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp5ZaAlmo8x4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "from os.path import dirname, join as pjoin\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as keras\n",
        "from tensorflow.keras import Model\n",
        "import cv2\n",
        "import random\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNKXlmiV0KhR"
      },
      "source": [
        "#Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfxLH48kj83g"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "from os.path import dirname, join as pjoin\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def unison_shuffle(a,b):\n",
        "    inx=np.random.permutation(a.shape[0])\n",
        "    return a[inx],b[inx]\n",
        "\n",
        "def data_loader(train_input_dir, train_mask_dir, test_input_dir, test_mask_dir):\n",
        "    \n",
        "    #should there be only one direction?\n",
        "    #how are we supposed to get the other 4 directions of train test and images and masks for each\n",
        "\n",
        "    train_input_img_paths = sorted(\n",
        "        [\n",
        "            os.path.join(train_input_dir, fname)\n",
        "            for fname in os.listdir(train_input_dir)\n",
        "            if fname.endswith(\".jpg\")\n",
        "        ]\n",
        "    )\n",
        "    train_input_array_list = [cv2.resize(mpimg.imread(str_index), (256,256))\n",
        "                  for str_index in train_input_img_paths]\n",
        "\n",
        "    train_mask_img_paths = sorted(\n",
        "        [\n",
        "            os.path.join(train_mask_dir, fname)\n",
        "            for fname in os.listdir(train_mask_dir)\n",
        "            if fname.endswith(\".png\")\n",
        "        ]\n",
        "    )\n",
        "    train_mask_array_list = [cv2.resize(mpimg.imread(str_index), (256,256))\n",
        "                  for str_index in train_mask_img_paths]\n",
        "\n",
        "\n",
        "    test_input_img_paths = sorted(\n",
        "        [\n",
        "            os.path.join(test_input_dir, fname)\n",
        "            for fname in os.listdir(test_input_dir)\n",
        "            if fname.endswith(\".jpg\")\n",
        "        ]\n",
        "    )\n",
        "    test_input_array_list = [cv2.resize(mpimg.imread(str_index), (256,256))\n",
        "                  for str_index in test_input_img_paths]\n",
        "\n",
        "    test_mask_img_paths = sorted(\n",
        "        [\n",
        "            os.path.join(test_mask_dir, fname)\n",
        "            for fname in os.listdir(test_mask_dir)\n",
        "            if fname.endswith(\".png\")\n",
        "        ]\n",
        "    )\n",
        "    test_mask_array_list = [cv2.resize(mpimg.imread(str_index), (256,256))\n",
        "                  for str_index in test_mask_img_paths]\n",
        "\n",
        "\n",
        "    X_train_list, Y_train_list = train_input_array_list, train_mask_array_list\n",
        "    X_test_list, Y_test_list = test_input_array_list, test_mask_array_list\n",
        "\n",
        "    X_train = np.array(X_train_list)\n",
        "    X_test = np.array(X_test_list)\n",
        "    Y_train = np.array(Y_train_list)\n",
        "    Y_test = np.array(Y_test_list)\n",
        "\n",
        "    X_train = X_train/255\n",
        "    X_test = X_test/255\n",
        "    Y_train = Y_train/255\n",
        "    Y_test = Y_test/255\n",
        "\n",
        "\n",
        "    # datagen = ImageDataGenerator(\n",
        "    # rotation_range=45,\n",
        "    # horizontal_flip=True,\n",
        "    # vertical_flip=True,\n",
        "    # zoom_range=0.4,\n",
        "    # validation_split=0.2,\n",
        "    # rescale=1./255\n",
        "    # )\n",
        "    print(\"Xtrain shape\", X_train.shape)\n",
        "    print(\"ytrain shape\", Y_train.shape)\n",
        "    print(\"Xtest shape\", X_test.shape)\n",
        "    print(\"ytest shape\", Y_test.shape)\n",
        "    Y_train = np.expand_dims(Y_train, axis=3)\n",
        "    Y_test = np.expand_dims(Y_test, axis=3)\n",
        "\n",
        "    image_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    # width_shift_range=10,\n",
        "    # height_shift_range=10,\n",
        "    #brightness_range=(0.3, 1.8),\n",
        "    shear_range=5,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode = 'wrap',\n",
        "    horizontal_flip = True\n",
        "    )\n",
        "\n",
        "    mask_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    # width_shift_range=10,\n",
        "    # height_shift_range=10,\n",
        "    #brightness_range=(0.3, 1.8),\n",
        "    shear_range=5,\n",
        "    zoom_range=0.2,\n",
        "    fill_mode = 'wrap',\n",
        "    horizontal_flip = True\n",
        "    )\n",
        "\n",
        "    datagen_test = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.4\n",
        "    )\n",
        "\n",
        "    print(\"salam\")\n",
        "\n",
        "    # trainX, trainy = unison_shuffle(trainX,trainy)\n",
        "    # testX, testy = unison_shuffle(testX,testy)\n",
        "\n",
        "  # trainX, valX, trainy, validy = train_test_split(data, labels, test_size=0.33, shuffle= True)\n",
        "\n",
        "    seed = 909\n",
        "    image_datagen.fit(X_train[:int(X_train.shape[0]*0.8)], augment=True, seed=seed)\n",
        "    mask_datagen.fit(Y_train[:int(Y_train.shape[0]*0.8)], augment=True, seed=seed)\n",
        "\n",
        "    x=image_datagen.flow(X_train[:int(X_train.shape[0]*0.8)],batch_size=32,shuffle=True, seed=seed)\n",
        "    y=mask_datagen.flow(Y_train[:int(Y_train.shape[0]*0.8)],batch_size=32,shuffle=True, seed=seed)\n",
        "\n",
        "\n",
        "\n",
        "# Creating the validation Image and Mask generator\n",
        "    image_datagen_val = ImageDataGenerator()\n",
        "    mask_datagen_val = ImageDataGenerator()\n",
        "\n",
        "    image_datagen_val.fit(X_train[int(X_train.shape[0]*0.8):], augment=True, seed=seed)\n",
        "    mask_datagen_val.fit(Y_train[int(Y_train.shape[0]*0.8):], augment=True, seed=seed)\n",
        "\n",
        "    x_val=image_datagen_val.flow(X_train[int(X_train.shape[0]*0.8):],batch_size=32,shuffle=True, seed=seed)\n",
        "    y_val=mask_datagen_val.flow(Y_train[int(Y_train.shape[0]*0.8):],batch_size=32,shuffle=True, seed=seed)\n",
        "\n",
        "    # traingen=datagen.flow(trainX,trainy,batch_size=8,subset='training')\n",
        "    # valgen=datagen.flow(trainX,trainy,batch_size=8,subset='validation')\n",
        "    # testgen=datagen.flow(testX,testy,batch_size=8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    traingen = (pair for pair in zip(x, y))\n",
        "    valgen = (pair for pair in zip(x_val, y_val))\n",
        "    return traingen,valgen,X_test, Y_test\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaYuVjMxkKFx"
      },
      "source": [
        "# UNET1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "641LE7dLkJp1"
      },
      "source": [
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_resnet50_unet(n_classes,input_shape):\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(input_shape, name=\"input_1\")\n",
        "\n",
        "    \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
        "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = resnet50.get_layer(\"input_1\").output           ## (512 x 512)\n",
        "    s2 = resnet50.get_layer(\"conv1_relu\").output        ## (256 x 256)\n",
        "    s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (128 x 128)\n",
        "    s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (64 x 64)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (32 x 32)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                     ## (64 x 64)\n",
        "    d2 = decoder_block(d1, s3, 256)                     ## (128 x 128)\n",
        "    d3 = decoder_block(d2, s2, 128)                     ## (256 x 256)\n",
        "    d4 = decoder_block(d3, s1, 64)                      ## (512 x 512)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    \n",
        "\n",
        "    model = Model(inputs, outputs, name=\"ResNet50_U-Net\")\n",
        "    return model\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMeJ1byQT7u3"
      },
      "source": [
        "# UNET2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fep1usXUg8mH"
      },
      "source": [
        "\n",
        "\n",
        "# # Unet model \n",
        "\n",
        "# def unet(input_size):   \n",
        "#     kinit = 'glorot_normal'\n",
        "#     def UnetConv2D(input, outdim, is_batchnorm, name):\n",
        "# \t    x = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_1')(input)\n",
        "# \t    if is_batchnorm:\n",
        "# \t\t    x =BatchNormalization(name=name + '_1_bn')(x)\n",
        "# \t    x = Activation('relu',name=name + '_1_act')(x)\n",
        "\n",
        "# \t    x = Conv2D(outdim, (3, 3), strides=(1, 1), kernel_initializer=kinit, padding=\"same\", name=name+'_2')(x)\n",
        "# \t    if is_batchnorm:\n",
        "# \t\t    x = BatchNormalization(name=name + '_2_bn')(x)\n",
        "# \t      x = Activation('relu', name=name + '_2_act')(x)\n",
        "# \t    return x\n",
        "#     inputs = Input(shape=input_size)\n",
        "#     conv1 = UnetConv2D(inputs, 32, is_batchnorm=True, name='conv1')\n",
        "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    \n",
        "#     conv2 = UnetConv2D(pool1, 64, is_batchnorm=True, name='conv2')\n",
        "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "#     conv3 = UnetConv2D(pool2, 128, is_batchnorm=True, name='conv3')\n",
        "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "#     conv4 = UnetConv2D(pool3, 256, is_batchnorm=True, name='conv4')\n",
        "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "#     conv5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer=kinit, padding='same')(pool4)\n",
        "#     conv5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer=kinit, padding='same')(conv5)\n",
        "\n",
        "#     up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), kernel_initializer=kinit, padding='same')(conv5), conv4], axis=3)\n",
        "#     conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "#     conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "#     up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "#     conv7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kinit, padding='same')(up7)\n",
        "#     conv7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kinit, padding='same')(conv7)\n",
        "\n",
        "#     up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), kernel_initializer=kinit, padding='same')(conv7), conv2], axis=3)\n",
        "#     conv8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kinit, padding='same')(up8)\n",
        "\n",
        "#     up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), kernel_initializer=kinit, padding='same')(conv8), conv1], axis=3)\n",
        "#     conv9 = Conv2D(32, (3, 3), activation='relu',  kernel_initializer=kinit, padding='same')(up9)\n",
        "#     conv9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer=kinit, padding='same')(conv9)\n",
        "#     conv10 = Conv2D(1, (1, 1), activation='sigmoid', name='final')(conv9)\n",
        "\n",
        "#     model = Model(inputs=[inputs], outputs=[conv10])\n",
        "#     return model\n",
        "# model = unet((256, 256, 3))\n",
        "# tf.keras.utils.plot_model(model,dpi=60, expand_nested=True, show_layer_names=False,show_shapes=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYZ8598BUA4h",
        "outputId": "2356b2a6-83f5-49df-d610-c56ce4eebc22"
      },
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "        numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "        denominator = tf.reduce_sum(y_true + y_pred)\n",
        "        return numerator / (denominator + tf.keras.backend.epsilon())\n",
        "\n",
        "\n",
        "model = build_resnet50_unet(2,(256,256,3))\n",
        "\n",
        "loss=\"binary_crossentropy\"\n",
        "#loss = 'sparse_categorical_crossentropy'\n",
        "\n",
        "model.compile(optimizer = Adam(lr = 1e-4), loss = loss, \n",
        "              metrics = ['accuracy',dice_coefficient])\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuvrZSPCZUEq",
        "outputId": "39277298-686b-49e7-c579-8db88eb28104"
      },
      "source": [
        "train_gen,val_gen, testX, testy = data_loader('/content/ISBI2016_ISIC_Part1_Training_Data', '/content/ISBI2016_ISIC_Part1_Training_GroundTruth',\n",
        "                                        '/content/ISBI2016_ISIC_Part1_Test_Data', '/content/ISBI2016_ISIC_Part1_Test_GroundTruth')\n",
        "\n",
        "train_step = 900*0.8/32\n",
        "val_step = 900*0.2/32\n",
        "\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=train_step, epochs=10,\n",
        "                              validation_data=val_gen, validation_steps=val_step)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xtrain shape (900, 256, 256, 3)\n",
            "ytrain shape (900, 256, 256)\n",
            "Xtest shape (379, 256, 256, 3)\n",
            "ytest shape (379, 256, 256)\n",
            "salam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 148s 4s/step - loss: 0.6938 - accuracy: 0.8490 - dice_coefficient: 0.0022 - val_loss: 2.4058 - val_accuracy: 0.9823 - val_dice_coefficient: 0.0022\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.3903 - accuracy: 0.8072 - dice_coefficient: 0.0022 - val_loss: 0.6864 - val_accuracy: 0.9580 - val_dice_coefficient: 0.0022\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.3071 - accuracy: 0.8252 - dice_coefficient: 0.0022 - val_loss: 0.6708 - val_accuracy: 0.9963 - val_dice_coefficient: 0.0021\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.2706 - accuracy: 0.9066 - dice_coefficient: 0.0021 - val_loss: 0.6327 - val_accuracy: 0.9862 - val_dice_coefficient: 0.0024\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.2514 - accuracy: 0.9409 - dice_coefficient: 0.0022 - val_loss: 0.5569 - val_accuracy: 0.8560 - val_dice_coefficient: 0.0022\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.2338 - accuracy: 0.9548 - dice_coefficient: 0.0021 - val_loss: 0.4764 - val_accuracy: 0.7664 - val_dice_coefficient: 0.0022\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.2204 - accuracy: 0.9738 - dice_coefficient: 0.0021 - val_loss: 0.4000 - val_accuracy: 0.7290 - val_dice_coefficient: 0.0023\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.2093 - accuracy: 0.9844 - dice_coefficient: 0.0021 - val_loss: 0.3336 - val_accuracy: 0.7184 - val_dice_coefficient: 0.0022\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.1995 - accuracy: 0.9864 - dice_coefficient: 0.0021 - val_loss: 0.2869 - val_accuracy: 0.6891 - val_dice_coefficient: 0.0024\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 68s 3s/step - loss: 0.1910 - accuracy: 0.9876 - dice_coefficient: 0.0021 - val_loss: 0.2497 - val_accuracy: 0.6910 - val_dice_coefficient: 0.0023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiESVhQblMyS"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}