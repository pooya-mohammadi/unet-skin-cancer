{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pfZzZofyZVB_",
   "metadata": {
    "id": "pfZzZofyZVB_"
   },
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3uUKOYfZUiA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3uUKOYfZUiA",
    "outputId": "1e927faf-42ef-421a-f8e8-7d640bfb6b07"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lCirzbPuZyuQ",
   "metadata": {
    "id": "lCirzbPuZyuQ"
   },
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "dataset_name = \"ISIC_2016\"\n",
    "train_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_Data.zip\"\n",
    "test_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_Data.zip\"\n",
    "mask_train_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Training_GroundTruth.zip\"\n",
    "mask_test_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part1_Test_GroundTruth.zip\"\n",
    "train_path = \"data/train\"\n",
    "test_path = \"data/test\"\n",
    "mask_train_path = \"data/mask_train\"\n",
    "mask_test_path = \"data/mask_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166bc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data/preprocessing.py \\\n",
    "--dataset_name $dataset_name \\\n",
    "--train_zip_url $train_zip_url \\\n",
    "--test_zip_url $test_zip_url \\\n",
    "--mask_train_zip_url $mask_train_zip_url \\\n",
    "--mask_test_zip_url $mask_test_zip_url \\\n",
    "--train_path $train_path \\\n",
    "--test_path $test_path \\\n",
    "--mask_train_path $mask_train_path \\\n",
    "--mask_test_path $mask_test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130c324",
   "metadata": {
    "id": "4130c324"
   },
   "source": [
    "# Training Models\n",
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from utils.group_metrics import get_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "dataset_name = \"ISIC_2016\"\n",
    "model_names = [\n",
    "    'r2unet_cbam',\n",
    "    'r2unet',\n",
    "    'unet_res50',\n",
    "    'unet_conv_deconv',\n",
    "    'unet_attention_gate', # This model is not deterministic\n",
    "    'unet_cbam',\n",
    "    'unet_cbam_gate',\n",
    "    'unet_pyramid_cbam_gate',\n",
    "    \"mcg_unet\",\n",
    "    'double_unet',\n",
    "    ]\n",
    "               \n",
    "save_path = \"saved_models/\"\n",
    "train_identifier = \"usual\"\n",
    "multi_train = 1 # Run model for several times to estmiate std and mean metrics!\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "img_size = (256, 256)\n",
    "img_channel = 3\n",
    "loss = \"dice_loss\"\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "min_lr = 1e-5\n",
    "\n",
    "# callbacks\n",
    "reduce_lr_patience = 15\n",
    "reduce_lr_factor = 0.1\n",
    "early_stopping_p = 30\n",
    "\n",
    "seeds = 1234\n",
    "verbose = 1\n",
    "\n",
    "# Augmentation\n",
    "hair_aug_p = 0\n",
    "hair_rmv_p = 0\n",
    "\n",
    "mosaic_p = 0\n",
    "cutmix_p = 0\n",
    "cutmix_beta = 0\n",
    "\n",
    "# Constant\n",
    "hue_shift_limit = 1\n",
    "sat_shift_limit = 0\n",
    "contrast_limit = 0.1\n",
    "brightness_limit = 0.1\n",
    "hue_p = 0.5\n",
    "contrast_p = 0.5\n",
    "brightness_p = 0.5\n",
    "random_rotate_p = 0.5\n",
    "p_horizontal_flip = 0.5\n",
    "p_vertical_flip = 0.5\n",
    "p_center_crop = 0.5\n",
    "\n",
    "metrics_names = (\n",
    "    \"dice_loss\", \n",
    "    \"dice_score\",\n",
    "    \"focal_tversky_loss\",\n",
    "    \"iou\",\n",
    "    \"jaccard_loss\",\n",
    "    \"loss\",\n",
    "    \"val_dice_loss\",\n",
    "    \"val_dice_score\",\n",
    "    \"val_focal_tversky_loss\",\n",
    "    \"val_iou\",\n",
    "    \"val_jaccard_loss\",\n",
    "    \"val_loss\"\n",
    "         )\n",
    "metrics_operators = (min, max, min, max, min, min, min, max, min, max, min, min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d041a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_print_mean_std(save_path, dataset_name, model, train_identifier, multi_train, metrics_names, metrics_operators, model_path):\n",
    "    try:\n",
    "        csv_addresses = [\n",
    " os.path.join(save_path, dataset_name, model, f\"{train_identifier}_{n}\", \"exp_1\" , \"csv_logger_train.csv\") for n in range(multi_train)   \n",
    "]\n",
    "        metrics = get_mean_std(csv_addresses, \n",
    "                       arguments=metrics_names,\n",
    "                       operators=metrics_operators,\n",
    "                       save_path=os.path.join(save_path, dataset_name, model, f\"{train_identifier}_mean_std_metrics.csv\")\n",
    "                      )\n",
    "        for name, metric in metrics.items():\n",
    "            print(f\"[INFO] Model: {model} == > {name}: {metric}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e} raised for {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "# !PYTHONHASHSEED=0\n",
    "# !TF_DETERMINISTIC_OPS=0\n",
    "# !TF_CUDNN_DETERMINISTIC=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from utils.group_metrics import get_mean_std\n",
    "\n",
    "for model in model_names:\n",
    "    model_path = os.path.join(save_path, dataset_name, model)\n",
    "    for n in range(multi_train):\n",
    "        seed = seeds + n\n",
    "        saved_path_name = f\"{train_identifier}_{n}\"\n",
    "        iter_model = os.path.join(model_path, saved_path_name)\n",
    "        print(f\"[INFO] Removing old model checkpoints: {iter_model}!!\")\n",
    "        shutil.rmtree(iter_model) if os.path.isdir(iter_model) else print(f'[INFO] {iter_model} does not exist!')\n",
    "        !python train.py \\\n",
    "        --model $model --dataset_name $dataset_name \\\n",
    "        --save_path $save_path \\\n",
    "        --save_path_name $saved_path_name \\\n",
    "        --epochs $epochs \\\n",
    "        --lr $lr \\\n",
    "        --min_lr $min_lr \\\n",
    "        --reduce_lr_patience $reduce_lr_patience \\\n",
    "        --reduce_lr_factor $reduce_lr_factor \\\n",
    "        --early_stopping_p $early_stopping_p \\\n",
    "        --hair_aug_p $hair_aug_p \\\n",
    "        --hair_rmv_p $hair_rmv_p \\\n",
    "        --random_rotate_p $random_rotate_p \\\n",
    "        --p_horizontal_flip $p_horizontal_flip \\\n",
    "        --p_vertical_flip $p_vertical_flip \\\n",
    "        --p_center_crop $p_center_crop \\\n",
    "        --mosaic_p $mosaic_p \\\n",
    "        --cutmix_p $cutmix_p \\\n",
    "        --cutmix_beta $cutmix_beta \\\n",
    "        --seed $seed\n",
    "    \n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "    save_print_mean_std(save_path, dataset_name, model, train_identifier, multi_train, metrics_names, metrics_operators, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe10a76",
   "metadata": {},
   "source": [
    "## With cutmix and Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1dc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identifier = \"usual_cutmix_mosaic\"\n",
    "\n",
    "# Augmentation\n",
    "hair_aug_p = 0\n",
    "hair_rmv_p = 0\n",
    "\n",
    "mosaic_p = 0.5\n",
    "cutmix_p = 0.5\n",
    "cutmix_beta = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_names:\n",
    "    model_path = os.path.join(save_path, dataset_name, model)\n",
    "    for n in range(multi_train):\n",
    "        seed = seeds + n\n",
    "        saved_path_name = f\"{train_identifier}_{n}\"\n",
    "        iter_model = os.path.join(model_path, saved_path_name)\n",
    "        print(f\"[INFO] Removing old model checkpoints: {iter_model}!!\")\n",
    "        shutil.rmtree(iter_model) if os.path.isdir(iter_model) else print(f'[INFO] {iter_model} does not exist!')\n",
    "        !python train.py \\\n",
    "        --model $model --dataset_name $dataset_name \\\n",
    "        --save_path $save_path \\\n",
    "        --save_path_name $saved_path_name \\\n",
    "        --epochs $epochs \\\n",
    "        --lr $lr \\\n",
    "        --min_lr $min_lr \\\n",
    "        --reduce_lr_patience $reduce_lr_patience \\\n",
    "        --reduce_lr_factor $reduce_lr_factor \\\n",
    "        --early_stopping_p $early_stopping_p \\\n",
    "        --hair_aug_p $hair_aug_p \\\n",
    "        --hair_rmv_p $hair_rmv_p \\\n",
    "        --random_rotate_p $random_rotate_p \\\n",
    "        --p_horizontal_flip $p_horizontal_flip \\\n",
    "        --p_vertical_flip $p_vertical_flip \\\n",
    "        --p_center_crop $p_center_crop \\\n",
    "        --mosaic_p $mosaic_p \\\n",
    "        --cutmix_p $cutmix_p \\\n",
    "        --cutmix_beta $cutmix_beta \\\n",
    "        --seed $seed\n",
    "    \n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "    save_print_mean_std(save_path, dataset_name, model, train_identifier, multi_train, metrics_names, metrics_operators, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea6501f",
   "metadata": {},
   "source": [
    "# With Cutmix & Mosaic & hair aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d71bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identifier = \"usual_cutmix_mosaic_hair_aug\"\n",
    "\n",
    "# Augmentation\n",
    "hair_aug_p = 0.5\n",
    "hair_rmv_p = 0\n",
    "\n",
    "mosaic_p = 0.5\n",
    "cutmix_p = 0.5\n",
    "cutmix_beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_names:\n",
    "    model_path = os.path.join(save_path, dataset_name, model)\n",
    "    for n in range(multi_train):\n",
    "        seed = seeds + n\n",
    "        saved_path_name = f\"{train_identifier}_{n}\"\n",
    "        iter_model = os.path.join(model_path, saved_path_name)\n",
    "        print(f\"[INFO] Removing old model checkpoints: {iter_model}!!\")\n",
    "        shutil.rmtree(iter_model) if os.path.isdir(iter_model) else print(f'[INFO] {iter_model} does not exist!')\n",
    "        !python train.py \\\n",
    "        --model $model --dataset_name $dataset_name \\\n",
    "        --save_path $save_path \\\n",
    "        --save_path_name $saved_path_name \\\n",
    "        --epochs $epochs \\\n",
    "        --lr $lr \\\n",
    "        --min_lr $min_lr \\\n",
    "        --reduce_lr_patience $reduce_lr_patience \\\n",
    "        --reduce_lr_factor $reduce_lr_factor \\\n",
    "        --early_stopping_p $early_stopping_p \\\n",
    "        --hair_aug_p $hair_aug_p \\\n",
    "        --hair_rmv_p $hair_rmv_p \\\n",
    "        --random_rotate_p $random_rotate_p \\\n",
    "        --p_horizontal_flip $p_horizontal_flip \\\n",
    "        --p_vertical_flip $p_vertical_flip \\\n",
    "        --p_center_crop $p_center_crop \\\n",
    "        --mosaic_p $mosaic_p \\\n",
    "        --cutmix_p $cutmix_p \\\n",
    "        --cutmix_beta $cutmix_beta \\\n",
    "        --seed $seed\n",
    "    \n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "    save_print_mean_std(save_path, dataset_name, model, train_identifier, multi_train, metrics_names, metrics_operators, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f78df8",
   "metadata": {},
   "source": [
    "# With Cutmix & Mosaic & hair rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identifier = \"usual_cutmix_mosaic_hair_rmv\"\n",
    "\n",
    "# Augmentation\n",
    "hair_aug_p = 0\n",
    "hair_rmv_p = 0.5\n",
    "\n",
    "mosaic_p = 0.5\n",
    "cutmix_p = 0.5\n",
    "cutmix_beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_names:\n",
    "    model_path = os.path.join(save_path, dataset_name, model)\n",
    "    for n in range(multi_train):\n",
    "        seed = seeds + n\n",
    "        saved_path_name = f\"{train_identifier}_{n}\"\n",
    "        iter_model = os.path.join(model_path, saved_path_name)\n",
    "        print(f\"[INFO] Removing old model checkpoints: {iter_model}!!\")\n",
    "        shutil.rmtree(iter_model) if os.path.isdir(iter_model) else print(f'[INFO] {iter_model} does not exist!')\n",
    "        !python train.py \\\n",
    "        --model $model --dataset_name $dataset_name \\\n",
    "        --save_path $save_path \\\n",
    "        --save_path_name $saved_path_name \\\n",
    "        --epochs $epochs \\\n",
    "        --lr $lr \\\n",
    "        --min_lr $min_lr \\\n",
    "        --reduce_lr_patience $reduce_lr_patience \\\n",
    "        --reduce_lr_factor $reduce_lr_factor \\\n",
    "        --early_stopping_p $early_stopping_p \\\n",
    "        --hair_aug_p $hair_aug_p \\\n",
    "        --hair_rmv_p $hair_rmv_p \\\n",
    "        --random_rotate_p $random_rotate_p \\\n",
    "        --p_horizontal_flip $p_horizontal_flip \\\n",
    "        --p_vertical_flip $p_vertical_flip \\\n",
    "        --p_center_crop $p_center_crop \\\n",
    "        --mosaic_p $mosaic_p \\\n",
    "        --cutmix_p $cutmix_p \\\n",
    "        --cutmix_beta $cutmix_beta \\\n",
    "        --seed $seed\n",
    "    \n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "        print(f\"\\n-----------------------------train {n} is done! for model: {model} ----------------------------------\\n\")\n",
    "    save_print_mean_std(save_path, dataset_name, model, train_identifier, multi_train, metrics_names, metrics_operators, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49feee3c",
   "metadata": {},
   "source": [
    "_:)_"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
