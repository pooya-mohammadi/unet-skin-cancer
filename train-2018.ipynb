{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec06fe58",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<!-- <a href=\"https://colab.research.google.com/github/i1idan/schizophrenia-diagnosis-eeg-signals/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B7YlhS4gYc8s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7YlhS4gYc8s",
    "outputId": "7ed228ec-718f-43ae-bf46-9511ead2581e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FB7LuLHBlpvM",
   "metadata": {
    "id": "FB7LuLHBlpvM"
   },
   "source": [
    "# Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35c532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d35c532",
    "outputId": "cb3b1d58-fdfb-48f5-9fa6-dadc8a12fc24"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/i1idan/schizophrenia-diagnosis-eeg-signals.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6X3Blwu5ZKWq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6X3Blwu5ZKWq",
    "outputId": "77e2207f-1941-4df9-d692-dd19d7811671"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/schizophrenia-diagnosis-eeg-signals')\n",
    "# !git pull origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pfZzZofyZVB_",
   "metadata": {
    "id": "pfZzZofyZVB_"
   },
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3uUKOYfZUiA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3uUKOYfZUiA",
    "outputId": "1e927faf-42ef-421a-f8e8-7d640bfb6b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deep_utils>=0.8.20 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (0.8.20)\n",
      "Requirement already satisfied: tensorflow>=2.8.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.8.0)\n",
      "Collecting keras_unet_collection\n",
      "  Downloading keras_unet_collection-0.1.13-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 51 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.27.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from deep_utils>=0.8.20->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from deep_utils>=0.8.20->-r requirements.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.58 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from deep_utils>=0.8.20->-r requirements.txt (line 1)) (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from deep_utils>=0.8.20->-r requirements.txt (line 1)) (1.21.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.43.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (3.19.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: setuptools in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (58.0.4)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (13.0.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (4.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.37.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from requests>=2.27.1->deep_utils>=0.8.20->-r requirements.txt (line 1)) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from requests>=2.27.1->deep_utils>=0.8.20->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from requests>=2.27.1->deep_utils>=0.8.20->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from requests>=2.27.1->deep_utils>=0.8.20->-r requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->-r requirements.txt (line 2)) (3.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: keras-unet-collection\n",
      "Successfully installed keras-unet-collection-0.1.13\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lCirzbPuZyuQ",
   "metadata": {
    "id": "lCirzbPuZyuQ"
   },
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35dc016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018\n",
    "dataset_name = \"ISIC_2018\"\n",
    "train_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Training_Input.zip\"\n",
    "test_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Test_Input.zip\"\n",
    "val_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Validation_Input.zip\"\n",
    "mask_train_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Training_GroundTruth.zip\"\n",
    "mask_val_zip_url = \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Validation_GroundTruth.zip\"\n",
    "train_path = \"data/train\"\n",
    "test_path = \"data/test\"\n",
    "val_path = \"data/val\"\n",
    "mask_train_path = \"data/mask_train\"\n",
    "mask_val_path = \"data/mask_val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ccc6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_name = train_zip_url.split(\"/\")[-1]\n",
    "\n",
    "import os\n",
    "os.path.isfile(zip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "166bc7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/deep_utils/vision/face_detection/ultralight/__init__.py:3: UserWarning: \n",
      "No module named 'deep_utils.vision.face_detection.ultralight.torch'. If you don't use UltralightTorchFaceDetector ignore this message.\n",
      "  UltralightTorchFaceDetector = import_module(\n",
      "/home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/deep_utils/vision/face_detection/ultralight/__init__.py:6: UserWarning: \n",
      "No module named 'deep_utils.vision.face_detection.ultralight.tf'. If you don't use UltralightTFFaceDetector ignore this message.\n",
      "  UltralightTFFaceDetector = import_module(\n",
      "[INFO] zip file: ISBI2016_ISIC_Part1_Training_Data doesn't exist! Unzipping ISBI2016_ISIC_Part1_Training_Data.zip\n",
      "[INFO] Successfully extracted ISBI2016_ISIC_Part1_Training_Data.zip to .!\n",
      "[INFO] zip file: ISBI2016_ISIC_Part1_Training_GroundTruth doesn't exist! Unzipping ISBI2016_ISIC_Part1_Training_GroundTruth.zip\n",
      "[INFO] Successfully extracted ISBI2016_ISIC_Part1_Training_GroundTruth.zip to .!\n",
      "[INFO] zip file: ISBI2016_ISIC_Part1_Test_Data doesn't exist! Unzipping ISBI2016_ISIC_Part1_Test_Data.zip\n",
      "[INFO] Successfully extracted ISBI2016_ISIC_Part1_Test_Data.zip to .!\n",
      "[INFO] zip file: ISBI2016_ISIC_Part1_Test_GroundTruth doesn't exist! Unzipping ISBI2016_ISIC_Part1_Test_GroundTruth.zip\n",
      "[INFO] Successfully extracted ISBI2016_ISIC_Part1_Test_GroundTruth.zip to .!\n",
      "[INFO] Preprocessing is successfully done!\n"
     ]
    }
   ],
   "source": [
    "!python data/preprocessing.py \\\n",
    "--dataset_name $dataset_name \\\n",
    "--train_zip_url $train_zip_url \\\n",
    "--test_zip_url $test_zip_url \\\n",
    "--mask_train_zip_url $mask_train_zip_url \\\n",
    "--mask_test_zip_url $mask_test_zip_url \\\n",
    "--train_path $train_path \\\n",
    "--test_path $test_path \\\n",
    "--mask_train_path $mask_train_path \\\n",
    "--mask_test_path $mask_test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130c324",
   "metadata": {
    "id": "4130c324"
   },
   "source": [
    "# Training Models\n",
    "## UnetRes50\n",
    "### Main params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3fd2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic\n",
    "dataset_name = \"ISIC_2018\"\n",
    "model = 'unet_res50'\n",
    "save_path = \"saved_models/\"\n",
    "train_identifier = \"usual\"\n",
    "multi_train = 3\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "img_size = (256, 256)\n",
    "img_channel = 3\n",
    "loss = \"dice_loss\"\n",
    "\n",
    "# optimizer\n",
    "optimizer = 'adam'\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-3\n",
    "min_lr = 1e-5\n",
    "\n",
    "# callbacks\n",
    "reduce_lr_patience = 10\n",
    "reduce_lr_factor = 0.1\n",
    "early_stopping_p = 25\n",
    "\n",
    "seeds = 1234\n",
    "verbose = 1\n",
    "\n",
    "# Augmentation\n",
    "hair_aug_p = 0\n",
    "hair_rmv_p = 0\n",
    "random_rotate_p = 0.5\n",
    "p_horizontal_flip = 0.5\n",
    "p_vertical_flip = 0.5\n",
    "p_center_crop = 0.5\n",
    "mosaic_p = 0\n",
    "cutmix_p = 0\n",
    "cutmix_beta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/deep_utils/vision/face_detection/ultralight/__init__.py:3: UserWarning: \n",
      "No module named 'deep_utils.vision.face_detection.ultralight.torch'. If you don't use UltralightTorchFaceDetector ignore this message.\n",
      "  UltralightTorchFaceDetector = import_module(\n",
      "/home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/deep_utils/vision/face_detection/ultralight/__init__.py:6: UserWarning: \n",
      "No module named 'deep_utils.vision.face_detection.ultralight.tf'. If you don't use UltralightTFFaceDetector ignore this message.\n",
      "  UltralightTFFaceDetector = import_module(\n",
      "2022-02-26 22:02:16.313099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.330304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.330439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "[INFO] Successfully created logger for SKIN-CANCER\n",
      "[INFO] Saving params!\n",
      "2022-02-26 22:02:16,331 - SKIN-CANCER - INFO - [INFO] Params are successfully saved in saved_models/ISIC_2016/unet_res50/usual_0/exp_2/params.txt!\n",
      "2022-02-26 22:02:16,331 - SKIN-CANCER - INFO - Chosen Model: unet_res50\n",
      "2022-02-26 22:02:16,331 - SKIN-CANCER - INFO -  Arguments: Namespace(optimizer='adam', batch_size=8, img_channel=3, transfer_learning_epochs=5, finetuning_epochs=10, epochs=50, lr=0.001, min_lr=1e-05, reduce_lr_patience=5, reduce_lr_factor=0.1, early_stopping_p=20, mlflow_source='./mlruns', cutmix_p=0.0, cutmix_beta=0.0, usual_aug_with_cutmix=False, hair_aug_p=0.0, hair_rmv_p=0.0, random_rotate_p=0.5, p_horizontal_flip=0.5, p_vertical_flip=0.5, p_center_crop=0.5, mosaic_p=0.0, loss='dice_loss', label_smoothing=0, focal_loss_gamma=2, pos_weight=1, neg_weight=1, train_path='data/train', test_path='data/test', mask_train_path='data/mask_train', mask_test_path='data/mask_test', val_path='data/val', mask_val_path='data/mask_val', verbose=1, save_path='saved_models/', dataset_name='ISIC_2016', seed=1234, img_size=(256, 256), save_path_name='usual_0', model='unet_res50')\n",
      "[INFO] Successfully created MLFLOW-Handler\n",
      "2022-02-26 22:02:16,386 - SKIN-CANCER - INFO - Data Loader is successfully loaded!\n",
      "2022-02-26 22:02:16.395035: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-26 22:02:16.395251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.395382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.395446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.651735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.651872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.651958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:02:16.652012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21805 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Model: \"ResNet50_U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['conv4_block6_out[0][0]']       \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 512)  2048       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 512)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['activation_1[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['activation_3[0][0]']           \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 19  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                2)                                'conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 12  221312      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 12  147584      ['activation_4[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128, 128, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['activation_5[0][0]']           \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 67  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 64  38656       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 256, 256, 64  256        ['conv2d_6[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 256, 256, 64  36928       ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 64  256        ['conv2d_7[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 256, 256, 1)  65          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,676,545\n",
      "Trainable params: 20,642,113\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "2022-02-26 22:02:17,297 - SKIN-CANCER - INFO - model: unet_res50 is successfully loaded!\n",
      "2022-02-26 22:02:17.298041: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-02-26 22:02:17.298053: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-02-26 22:02:17.298069: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
      "2022-02-26 22:02:17.298207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.6/lib64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-26 22:02:17.356286: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-02-26 22:02:17.356444: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "[INFO] Successfully created following callbacks [model_checkpoint, reduce_lr, early_stop, csv_logger, tensorboard]\n",
      "2022-02-26 22:02:17,359 - SKIN-CANCER - INFO - loss: dice_loss is successfully created!\n",
      "2022-02-26 22:02:17,363 - SKIN-CANCER - INFO - Start train for saved_models/ISIC_2016/unet_res50/usual_0/exp_2\n",
      "Epoch 1/50\n",
      "2022-02-26 22:02:20.300097: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8301\n",
      " 1/90 [..............................] - ETA: 6:59 - loss: 0.6835 - dice_score: 0.3165 - iou: 0.1880 - dice_loss: 0.6835 - jaccard_loss: 0.7197 - focal_tversky_loss: 0.68972022-02-26 22:02:22.323203: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-02-26 22:02:22.323223: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-02-26 22:02:22.948457: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-02-26 22:02:22.948878: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "2022-02-26 22:02:22.965128: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1686 callback api events and 1694 activity events. \n",
      "2022-02-26 22:02:22.978232: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-02-26 22:02:22.994644: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22\n",
      "\n",
      "2022-02-26 22:02:23.008377: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22/ai.trace.json.gz\n",
      "2022-02-26 22:02:23.034032: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22\n",
      "\n",
      "2022-02-26 22:02:23.037353: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22/ai.memory_profile.json.gz\n",
      "2022-02-26 22:02:23.038500: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22\n",
      "Dumped tool data for xplane.pb to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22/ai.xplane.pb\n",
      "Dumped tool data for overview_page.pb to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22/ai.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22/ai.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22/ai.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_02_22/ai.kernel_stats.pb\n",
      "\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2254 - dice_score: 0.7746 - iou: 0.6416 - dice_loss: 0.2254 - jaccard_loss: 0.2964 - focal_tversky_loss: 0.3008\n",
      "Epoch 00001: val_loss improved from inf to 0.99301, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "2022-02-26 22:02:52.924823: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "90/90 [==============================] - 39s 387ms/step - loss: 0.2254 - dice_score: 0.7746 - iou: 0.6416 - dice_loss: 0.2254 - jaccard_loss: 0.2964 - focal_tversky_loss: 0.3008 - val_loss: 0.9930 - val_dice_score: 0.0070 - val_iou: 0.0035 - val_dice_loss: 0.9930 - val_jaccard_loss: 0.9964 - val_focal_tversky_loss: 0.9962 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1506 - dice_score: 0.8494 - iou: 0.7411 - dice_loss: 0.1506 - jaccard_loss: 0.2401 - focal_tversky_loss: 0.2372\n",
      "Epoch 00002: val_loss improved from 0.99301 to 0.98594, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 34s 376ms/step - loss: 0.1506 - dice_score: 0.8494 - iou: 0.7411 - dice_loss: 0.1506 - jaccard_loss: 0.2401 - focal_tversky_loss: 0.2372 - val_loss: 0.9859 - val_dice_score: 0.0141 - val_iou: 0.0071 - val_dice_loss: 0.9859 - val_jaccard_loss: 0.9927 - val_focal_tversky_loss: 0.9923 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1438 - dice_score: 0.8562 - iou: 0.7532 - dice_loss: 0.1438 - jaccard_loss: 0.2360 - focal_tversky_loss: 0.2308\n",
      "Epoch 00003: val_loss improved from 0.98594 to 0.48851, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 34s 378ms/step - loss: 0.1438 - dice_score: 0.8562 - iou: 0.7532 - dice_loss: 0.1438 - jaccard_loss: 0.2360 - focal_tversky_loss: 0.2308 - val_loss: 0.4885 - val_dice_score: 0.5115 - val_iou: 0.3537 - val_dice_loss: 0.4885 - val_jaccard_loss: 0.6429 - val_focal_tversky_loss: 0.4884 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1258 - dice_score: 0.8742 - iou: 0.7789 - dice_loss: 0.1258 - jaccard_loss: 0.2124 - focal_tversky_loss: 0.2135\n",
      "Epoch 00004: val_loss did not improve from 0.48851\n",
      "90/90 [==============================] - 28s 310ms/step - loss: 0.1258 - dice_score: 0.8742 - iou: 0.7789 - dice_loss: 0.1258 - jaccard_loss: 0.2124 - focal_tversky_loss: 0.2135 - val_loss: 0.9970 - val_dice_score: 0.0030 - val_iou: 0.0015 - val_dice_loss: 0.9970 - val_jaccard_loss: 0.9985 - val_focal_tversky_loss: 0.9984 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1254 - dice_score: 0.8746 - iou: 0.7812 - dice_loss: 0.1254 - jaccard_loss: 0.2124 - focal_tversky_loss: 0.2107\n",
      "Epoch 00005: val_loss did not improve from 0.48851\n",
      "90/90 [==============================] - 28s 310ms/step - loss: 0.1254 - dice_score: 0.8746 - iou: 0.7812 - dice_loss: 0.1254 - jaccard_loss: 0.2124 - focal_tversky_loss: 0.2107 - val_loss: 0.9995 - val_dice_score: 4.6117e-04 - val_iou: 2.2666e-04 - val_dice_loss: 0.9995 - val_jaccard_loss: 0.9998 - val_focal_tversky_loss: 0.9997 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1249 - dice_score: 0.8751 - iou: 0.7818 - dice_loss: 0.1249 - jaccard_loss: 0.2123 - focal_tversky_loss: 0.2119\n",
      "Epoch 00006: val_loss did not improve from 0.48851\n",
      "90/90 [==============================] - 28s 305ms/step - loss: 0.1249 - dice_score: 0.8751 - iou: 0.7818 - dice_loss: 0.1249 - jaccard_loss: 0.2123 - focal_tversky_loss: 0.2119 - val_loss: 0.9981 - val_dice_score: 0.0019 - val_iou: 9.5336e-04 - val_dice_loss: 0.9981 - val_jaccard_loss: 0.9990 - val_focal_tversky_loss: 0.9990 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1194 - dice_score: 0.8806 - iou: 0.7894 - dice_loss: 0.1194 - jaccard_loss: 0.2052 - focal_tversky_loss: 0.2050\n",
      "Epoch 00007: val_loss did not improve from 0.48851\n",
      "90/90 [==============================] - 28s 310ms/step - loss: 0.1194 - dice_score: 0.8806 - iou: 0.7894 - dice_loss: 0.1194 - jaccard_loss: 0.2052 - focal_tversky_loss: 0.2050 - val_loss: 0.7111 - val_dice_score: 0.2889 - val_iou: 0.1732 - val_dice_loss: 0.7111 - val_jaccard_loss: 0.8260 - val_focal_tversky_loss: 0.8214 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1147 - dice_score: 0.8853 - iou: 0.7967 - dice_loss: 0.1147 - jaccard_loss: 0.1987 - focal_tversky_loss: 0.1984\n",
      "Epoch 00008: val_loss did not improve from 0.48851\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "90/90 [==============================] - 28s 315ms/step - loss: 0.1147 - dice_score: 0.8853 - iou: 0.7967 - dice_loss: 0.1147 - jaccard_loss: 0.1987 - focal_tversky_loss: 0.1984 - val_loss: 0.5801 - val_dice_score: 0.4199 - val_iou: 0.2687 - val_dice_loss: 0.5801 - val_jaccard_loss: 0.7284 - val_focal_tversky_loss: 0.7191 - lr: 0.0010\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - ETA: 0s - loss: 0.1086 - dice_score: 0.8914 - iou: 0.8062 - dice_loss: 0.1086 - jaccard_loss: 0.1891 - focal_tversky_loss: 0.1968\n",
      "Epoch 00009: val_loss did not improve from 0.48851\n",
      "90/90 [==============================] - 28s 308ms/step - loss: 0.1086 - dice_score: 0.8914 - iou: 0.8062 - dice_loss: 0.1086 - jaccard_loss: 0.1891 - focal_tversky_loss: 0.1968 - val_loss: 0.5561 - val_dice_score: 0.4439 - val_iou: 0.2976 - val_dice_loss: 0.5561 - val_jaccard_loss: 0.6999 - val_focal_tversky_loss: 0.7005 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1017 - dice_score: 0.8983 - iou: 0.8175 - dice_loss: 0.1017 - jaccard_loss: 0.1780 - focal_tversky_loss: 0.1813\n",
      "Epoch 00010: val_loss improved from 0.48851 to 0.23403, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 34s 383ms/step - loss: 0.1017 - dice_score: 0.8983 - iou: 0.8175 - dice_loss: 0.1017 - jaccard_loss: 0.1780 - focal_tversky_loss: 0.1813 - val_loss: 0.2340 - val_dice_score: 0.7660 - val_iou: 0.6309 - val_dice_loss: 0.2340 - val_jaccard_loss: 0.3643 - val_focal_tversky_loss: 0.3796 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0966 - dice_score: 0.9034 - iou: 0.8259 - dice_loss: 0.0966 - jaccard_loss: 0.1693 - focal_tversky_loss: 0.1762\n",
      "Epoch 00011: val_loss improved from 0.23403 to 0.16587, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 34s 382ms/step - loss: 0.0966 - dice_score: 0.9034 - iou: 0.8259 - dice_loss: 0.0966 - jaccard_loss: 0.1693 - focal_tversky_loss: 0.1762 - val_loss: 0.1659 - val_dice_score: 0.8341 - val_iou: 0.7253 - val_dice_loss: 0.1659 - val_jaccard_loss: 0.2695 - val_focal_tversky_loss: 0.2855 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0883 - dice_score: 0.9117 - iou: 0.8388 - dice_loss: 0.0883 - jaccard_loss: 0.1563 - focal_tversky_loss: 0.1623\n",
      "Epoch 00012: val_loss improved from 0.16587 to 0.11103, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 33s 372ms/step - loss: 0.0883 - dice_score: 0.9117 - iou: 0.8388 - dice_loss: 0.0883 - jaccard_loss: 0.1563 - focal_tversky_loss: 0.1623 - val_loss: 0.1110 - val_dice_score: 0.8890 - val_iou: 0.8021 - val_dice_loss: 0.1110 - val_jaccard_loss: 0.1923 - val_focal_tversky_loss: 0.1984 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0822 - dice_score: 0.9178 - iou: 0.8492 - dice_loss: 0.0822 - jaccard_loss: 0.1458 - focal_tversky_loss: 0.1541\n",
      "Epoch 00013: val_loss improved from 0.11103 to 0.10215, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 34s 378ms/step - loss: 0.0822 - dice_score: 0.9178 - iou: 0.8492 - dice_loss: 0.0822 - jaccard_loss: 0.1458 - focal_tversky_loss: 0.1541 - val_loss: 0.1022 - val_dice_score: 0.8978 - val_iou: 0.8173 - val_dice_loss: 0.1022 - val_jaccard_loss: 0.1777 - val_focal_tversky_loss: 0.1781 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0813 - dice_score: 0.9187 - iou: 0.8508 - dice_loss: 0.0813 - jaccard_loss: 0.1444 - focal_tversky_loss: 0.1548\n",
      "Epoch 00014: val_loss did not improve from 0.10215\n",
      "90/90 [==============================] - 28s 307ms/step - loss: 0.0813 - dice_score: 0.9187 - iou: 0.8508 - dice_loss: 0.0813 - jaccard_loss: 0.1444 - focal_tversky_loss: 0.1548 - val_loss: 0.1159 - val_dice_score: 0.8841 - val_iou: 0.7953 - val_dice_loss: 0.1159 - val_jaccard_loss: 0.1995 - val_focal_tversky_loss: 0.1875 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0813 - dice_score: 0.9187 - iou: 0.8504 - dice_loss: 0.0813 - jaccard_loss: 0.1447 - focal_tversky_loss: 0.1542\n",
      "Epoch 00015: val_loss did not improve from 0.10215\n",
      "90/90 [==============================] - 28s 309ms/step - loss: 0.0813 - dice_score: 0.9187 - iou: 0.8504 - dice_loss: 0.0813 - jaccard_loss: 0.1447 - focal_tversky_loss: 0.1542 - val_loss: 0.1208 - val_dice_score: 0.8792 - val_iou: 0.7943 - val_dice_loss: 0.1208 - val_jaccard_loss: 0.2009 - val_focal_tversky_loss: 0.1879 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0768 - dice_score: 0.9232 - iou: 0.8580 - dice_loss: 0.0768 - jaccard_loss: 0.1374 - focal_tversky_loss: 0.1462\n",
      "Epoch 00016: val_loss did not improve from 0.10215\n",
      "90/90 [==============================] - 28s 305ms/step - loss: 0.0768 - dice_score: 0.9232 - iou: 0.8580 - dice_loss: 0.0768 - jaccard_loss: 0.1374 - focal_tversky_loss: 0.1462 - val_loss: 0.1126 - val_dice_score: 0.8874 - val_iou: 0.8026 - val_dice_loss: 0.1126 - val_jaccard_loss: 0.1927 - val_focal_tversky_loss: 0.1876 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0798 - dice_score: 0.9202 - iou: 0.8536 - dice_loss: 0.0798 - jaccard_loss: 0.1417 - focal_tversky_loss: 0.1491\n",
      "Epoch 00017: val_loss improved from 0.10215 to 0.10146, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 34s 381ms/step - loss: 0.0798 - dice_score: 0.9202 - iou: 0.8536 - dice_loss: 0.0798 - jaccard_loss: 0.1417 - focal_tversky_loss: 0.1491 - val_loss: 0.1015 - val_dice_score: 0.8985 - val_iou: 0.8188 - val_dice_loss: 0.1015 - val_jaccard_loss: 0.1766 - val_focal_tversky_loss: 0.1736 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0770 - dice_score: 0.9230 - iou: 0.8579 - dice_loss: 0.0770 - jaccard_loss: 0.1374 - focal_tversky_loss: 0.1471\n",
      "Epoch 00018: val_loss did not improve from 0.10146\n",
      "90/90 [==============================] - 28s 311ms/step - loss: 0.0770 - dice_score: 0.9230 - iou: 0.8579 - dice_loss: 0.0770 - jaccard_loss: 0.1374 - focal_tversky_loss: 0.1471 - val_loss: 0.1136 - val_dice_score: 0.8864 - val_iou: 0.8000 - val_dice_loss: 0.1136 - val_jaccard_loss: 0.1954 - val_focal_tversky_loss: 0.1929 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0751 - dice_score: 0.9249 - iou: 0.8609 - dice_loss: 0.0751 - jaccard_loss: 0.1346 - focal_tversky_loss: 0.1442\n",
      "Epoch 00019: val_loss improved from 0.10146 to 0.09623, saving model to saved_models/ISIC_2016/unet_res50/usual_0/exp_2/model\n",
      "90/90 [==============================] - 34s 378ms/step - loss: 0.0751 - dice_score: 0.9249 - iou: 0.8609 - dice_loss: 0.0751 - jaccard_loss: 0.1346 - focal_tversky_loss: 0.1442 - val_loss: 0.0962 - val_dice_score: 0.9038 - val_iou: 0.8267 - val_dice_loss: 0.0962 - val_jaccard_loss: 0.1689 - val_focal_tversky_loss: 0.1714 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0755 - dice_score: 0.9245 - iou: 0.8603 - dice_loss: 0.0755 - jaccard_loss: 0.1353 - focal_tversky_loss: 0.1441\n",
      "Epoch 00020: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0755 - dice_score: 0.9245 - iou: 0.8603 - dice_loss: 0.0755 - jaccard_loss: 0.1353 - focal_tversky_loss: 0.1441 - val_loss: 0.1005 - val_dice_score: 0.8995 - val_iou: 0.8193 - val_dice_loss: 0.1005 - val_jaccard_loss: 0.1763 - val_focal_tversky_loss: 0.1712 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0752 - dice_score: 0.9248 - iou: 0.8610 - dice_loss: 0.0752 - jaccard_loss: 0.1348 - focal_tversky_loss: 0.1436\n",
      "Epoch 00021: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0752 - dice_score: 0.9248 - iou: 0.8610 - dice_loss: 0.0752 - jaccard_loss: 0.1348 - focal_tversky_loss: 0.1436 - val_loss: 0.0973 - val_dice_score: 0.9027 - val_iou: 0.8247 - val_dice_loss: 0.0973 - val_jaccard_loss: 0.1716 - val_focal_tversky_loss: 0.1834 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0738 - dice_score: 0.9262 - iou: 0.8634 - dice_loss: 0.0738 - jaccard_loss: 0.1325 - focal_tversky_loss: 0.1417\n",
      "Epoch 00022: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 305ms/step - loss: 0.0738 - dice_score: 0.9262 - iou: 0.8634 - dice_loss: 0.0738 - jaccard_loss: 0.1325 - focal_tversky_loss: 0.1417 - val_loss: 0.1144 - val_dice_score: 0.8856 - val_iou: 0.7996 - val_dice_loss: 0.1144 - val_jaccard_loss: 0.1965 - val_focal_tversky_loss: 0.1732 - lr: 1.0000e-04\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - ETA: 0s - loss: 0.0736 - dice_score: 0.9264 - iou: 0.8636 - dice_loss: 0.0736 - jaccard_loss: 0.1322 - focal_tversky_loss: 0.1431\n",
      "Epoch 00023: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 303ms/step - loss: 0.0736 - dice_score: 0.9264 - iou: 0.8636 - dice_loss: 0.0736 - jaccard_loss: 0.1322 - focal_tversky_loss: 0.1431 - val_loss: 0.0980 - val_dice_score: 0.9020 - val_iou: 0.8262 - val_dice_loss: 0.0980 - val_jaccard_loss: 0.1698 - val_focal_tversky_loss: 0.1684 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0706 - dice_score: 0.9294 - iou: 0.8689 - dice_loss: 0.0706 - jaccard_loss: 0.1272 - focal_tversky_loss: 0.1369\n",
      "Epoch 00024: val_loss did not improve from 0.09623\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "90/90 [==============================] - 28s 307ms/step - loss: 0.0706 - dice_score: 0.9294 - iou: 0.8689 - dice_loss: 0.0706 - jaccard_loss: 0.1272 - focal_tversky_loss: 0.1369 - val_loss: 0.1126 - val_dice_score: 0.8874 - val_iou: 0.8075 - val_dice_loss: 0.1126 - val_jaccard_loss: 0.1888 - val_focal_tversky_loss: 0.1792 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0696 - dice_score: 0.9304 - iou: 0.8703 - dice_loss: 0.0696 - jaccard_loss: 0.1257 - focal_tversky_loss: 0.1392\n",
      "Epoch 00025: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 28s 307ms/step - loss: 0.0696 - dice_score: 0.9304 - iou: 0.8703 - dice_loss: 0.0696 - jaccard_loss: 0.1257 - focal_tversky_loss: 0.1392 - val_loss: 0.1037 - val_dice_score: 0.8963 - val_iou: 0.8166 - val_dice_loss: 0.1037 - val_jaccard_loss: 0.1798 - val_focal_tversky_loss: 0.1749 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0691 - dice_score: 0.9309 - iou: 0.8717 - dice_loss: 0.0691 - jaccard_loss: 0.1244 - focal_tversky_loss: 0.1343\n",
      "Epoch 00026: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 306ms/step - loss: 0.0691 - dice_score: 0.9309 - iou: 0.8717 - dice_loss: 0.0691 - jaccard_loss: 0.1244 - focal_tversky_loss: 0.1343 - val_loss: 0.1161 - val_dice_score: 0.8839 - val_iou: 0.8073 - val_dice_loss: 0.1161 - val_jaccard_loss: 0.1891 - val_focal_tversky_loss: 0.1866 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0712 - dice_score: 0.9288 - iou: 0.8683 - dice_loss: 0.0712 - jaccard_loss: 0.1278 - focal_tversky_loss: 0.1386\n",
      "Epoch 00027: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0712 - dice_score: 0.9288 - iou: 0.8683 - dice_loss: 0.0712 - jaccard_loss: 0.1278 - focal_tversky_loss: 0.1386 - val_loss: 0.1098 - val_dice_score: 0.8902 - val_iou: 0.8105 - val_dice_loss: 0.1098 - val_jaccard_loss: 0.1859 - val_focal_tversky_loss: 0.1814 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0670 - dice_score: 0.9330 - iou: 0.8749 - dice_loss: 0.0670 - jaccard_loss: 0.1211 - focal_tversky_loss: 0.1326\n",
      "Epoch 00028: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0670 - dice_score: 0.9330 - iou: 0.8749 - dice_loss: 0.0670 - jaccard_loss: 0.1211 - focal_tversky_loss: 0.1326 - val_loss: 0.1021 - val_dice_score: 0.8979 - val_iou: 0.8207 - val_dice_loss: 0.1021 - val_jaccard_loss: 0.1757 - val_focal_tversky_loss: 0.1767 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0668 - dice_score: 0.9332 - iou: 0.8755 - dice_loss: 0.0668 - jaccard_loss: 0.1206 - focal_tversky_loss: 0.1319\n",
      "Epoch 00029: val_loss did not improve from 0.09623\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "90/90 [==============================] - 27s 302ms/step - loss: 0.0668 - dice_score: 0.9332 - iou: 0.8755 - dice_loss: 0.0668 - jaccard_loss: 0.1206 - focal_tversky_loss: 0.1319 - val_loss: 0.1082 - val_dice_score: 0.8918 - val_iou: 0.8121 - val_dice_loss: 0.1082 - val_jaccard_loss: 0.1843 - val_focal_tversky_loss: 0.1782 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0671 - dice_score: 0.9329 - iou: 0.8748 - dice_loss: 0.0671 - jaccard_loss: 0.1211 - focal_tversky_loss: 0.1329\n",
      "Epoch 00030: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 28s 308ms/step - loss: 0.0671 - dice_score: 0.9329 - iou: 0.8748 - dice_loss: 0.0671 - jaccard_loss: 0.1211 - focal_tversky_loss: 0.1329 - val_loss: 0.1081 - val_dice_score: 0.8919 - val_iou: 0.8132 - val_dice_loss: 0.1081 - val_jaccard_loss: 0.1832 - val_focal_tversky_loss: 0.1792 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0680 - dice_score: 0.9320 - iou: 0.8735 - dice_loss: 0.0680 - jaccard_loss: 0.1224 - focal_tversky_loss: 0.1329\n",
      "Epoch 00031: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 306ms/step - loss: 0.0680 - dice_score: 0.9320 - iou: 0.8735 - dice_loss: 0.0680 - jaccard_loss: 0.1224 - focal_tversky_loss: 0.1329 - val_loss: 0.1070 - val_dice_score: 0.8930 - val_iou: 0.8142 - val_dice_loss: 0.1070 - val_jaccard_loss: 0.1823 - val_focal_tversky_loss: 0.1759 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0699 - dice_score: 0.9301 - iou: 0.8701 - dice_loss: 0.0699 - jaccard_loss: 0.1258 - focal_tversky_loss: 0.1370\n",
      "Epoch 00032: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0699 - dice_score: 0.9301 - iou: 0.8701 - dice_loss: 0.0699 - jaccard_loss: 0.1258 - focal_tversky_loss: 0.1370 - val_loss: 0.1115 - val_dice_score: 0.8885 - val_iou: 0.8093 - val_dice_loss: 0.1115 - val_jaccard_loss: 0.1871 - val_focal_tversky_loss: 0.1855 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0686 - dice_score: 0.9314 - iou: 0.8723 - dice_loss: 0.0686 - jaccard_loss: 0.1237 - focal_tversky_loss: 0.1359\n",
      "Epoch 00033: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 28s 308ms/step - loss: 0.0686 - dice_score: 0.9314 - iou: 0.8723 - dice_loss: 0.0686 - jaccard_loss: 0.1237 - focal_tversky_loss: 0.1359 - val_loss: 0.1133 - val_dice_score: 0.8867 - val_iou: 0.8114 - val_dice_loss: 0.1133 - val_jaccard_loss: 0.1851 - val_focal_tversky_loss: 0.1841 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0660 - dice_score: 0.9340 - iou: 0.8768 - dice_loss: 0.0660 - jaccard_loss: 0.1193 - focal_tversky_loss: 0.1303\n",
      "Epoch 00034: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 303ms/step - loss: 0.0660 - dice_score: 0.9340 - iou: 0.8768 - dice_loss: 0.0660 - jaccard_loss: 0.1193 - focal_tversky_loss: 0.1303 - val_loss: 0.1125 - val_dice_score: 0.8875 - val_iou: 0.8104 - val_dice_loss: 0.1125 - val_jaccard_loss: 0.1861 - val_focal_tversky_loss: 0.1791 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0677 - dice_score: 0.9323 - iou: 0.8738 - dice_loss: 0.0677 - jaccard_loss: 0.1223 - focal_tversky_loss: 0.1330\n",
      "Epoch 00035: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 302ms/step - loss: 0.0677 - dice_score: 0.9323 - iou: 0.8738 - dice_loss: 0.0677 - jaccard_loss: 0.1223 - focal_tversky_loss: 0.1330 - val_loss: 0.1092 - val_dice_score: 0.8908 - val_iou: 0.8119 - val_dice_loss: 0.1092 - val_jaccard_loss: 0.1845 - val_focal_tversky_loss: 0.1785 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0676 - dice_score: 0.9324 - iou: 0.8743 - dice_loss: 0.0676 - jaccard_loss: 0.1218 - focal_tversky_loss: 0.1337\n",
      "Epoch 00036: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 302ms/step - loss: 0.0676 - dice_score: 0.9324 - iou: 0.8743 - dice_loss: 0.0676 - jaccard_loss: 0.1218 - focal_tversky_loss: 0.1337 - val_loss: 0.1162 - val_dice_score: 0.8838 - val_iou: 0.8066 - val_dice_loss: 0.1162 - val_jaccard_loss: 0.1899 - val_focal_tversky_loss: 0.1859 - lr: 1.0000e-05\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - ETA: 0s - loss: 0.0675 - dice_score: 0.9325 - iou: 0.8742 - dice_loss: 0.0675 - jaccard_loss: 0.1217 - focal_tversky_loss: 0.1337\n",
      "Epoch 00037: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 300ms/step - loss: 0.0675 - dice_score: 0.9325 - iou: 0.8742 - dice_loss: 0.0675 - jaccard_loss: 0.1217 - focal_tversky_loss: 0.1337 - val_loss: 0.1154 - val_dice_score: 0.8846 - val_iou: 0.8048 - val_dice_loss: 0.1154 - val_jaccard_loss: 0.1916 - val_focal_tversky_loss: 0.1872 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0656 - dice_score: 0.9344 - iou: 0.8775 - dice_loss: 0.0656 - jaccard_loss: 0.1185 - focal_tversky_loss: 0.1289\n",
      "Epoch 00038: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0656 - dice_score: 0.9344 - iou: 0.8775 - dice_loss: 0.0656 - jaccard_loss: 0.1185 - focal_tversky_loss: 0.1289 - val_loss: 0.1017 - val_dice_score: 0.8983 - val_iou: 0.8230 - val_dice_loss: 0.1017 - val_jaccard_loss: 0.1735 - val_focal_tversky_loss: 0.1707 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0657 - dice_score: 0.9343 - iou: 0.8772 - dice_loss: 0.0657 - jaccard_loss: 0.1187 - focal_tversky_loss: 0.1310\n",
      "Epoch 00039: val_loss did not improve from 0.09623\n",
      "90/90 [==============================] - 28s 305ms/step - loss: 0.0657 - dice_score: 0.9343 - iou: 0.8772 - dice_loss: 0.0657 - jaccard_loss: 0.1187 - focal_tversky_loss: 0.1310 - val_loss: 0.1152 - val_dice_score: 0.8848 - val_iou: 0.8098 - val_dice_loss: 0.1152 - val_jaccard_loss: 0.1867 - val_focal_tversky_loss: 0.1805 - lr: 1.0000e-05\n",
      "2022-02-26 22:21:13,714 - SKIN-CANCER - INFO - Training is done model is saved in saved_models/ISIC_2016/unet_res50/usual_0/exp_2\n",
      "Evaluation\n",
      "48/48 [==============================] - 8s 175ms/step - loss: 0.1033 - dice_score: 0.8967 - iou: 0.8287 - dice_loss: 0.1033 - jaccard_loss: 0.1675 - focal_tversky_loss: 0.1621\n",
      "2022-02-26 22:21:22,138 - SKIN-CANCER - INFO - Test: Loss= 0.1033005639910698, Dice-Score: 0.8966994881629944, IoU: 0.8287282586097717, Dice_loss: 0.1033005639910698, jaccard_loss: 0.16754841804504395, focal_tversky_loss: 0.16214989125728607\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.0894 - dice_score: 0.9106 - iou: 0.8358 - dice_loss: 0.0894 - jaccard_loss: 0.1575 - focal_tversky_loss: 0.1160\n",
      "2022-02-26 22:21:26,392 - SKIN-CANCER - INFO - Successfully Saved figures!\n",
      "\n",
      "-----------------------------train 0 is done! ----------------------------------\n",
      "\n",
      "/home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/deep_utils/vision/face_detection/ultralight/__init__.py:3: UserWarning: \n",
      "No module named 'deep_utils.vision.face_detection.ultralight.torch'. If you don't use UltralightTorchFaceDetector ignore this message.\n",
      "  UltralightTorchFaceDetector = import_module(\n",
      "/home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/deep_utils/vision/face_detection/ultralight/__init__.py:6: UserWarning: \n",
      "No module named 'deep_utils.vision.face_detection.ultralight.tf'. If you don't use UltralightTFFaceDetector ignore this message.\n",
      "  UltralightTFFaceDetector = import_module(\n",
      "2022-02-26 22:21:30.410081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.437705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.437797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "[INFO] Successfully created logger for SKIN-CANCER\n",
      "[INFO] Saving params!\n",
      "2022-02-26 22:21:30,439 - SKIN-CANCER - INFO - [INFO] Params are successfully saved in saved_models/ISIC_2016/unet_res50/usual_1/exp_2/params.txt!\n",
      "2022-02-26 22:21:30,439 - SKIN-CANCER - INFO - Chosen Model: unet_res50\n",
      "2022-02-26 22:21:30,439 - SKIN-CANCER - INFO -  Arguments: Namespace(optimizer='adam', batch_size=8, img_channel=3, transfer_learning_epochs=5, finetuning_epochs=10, epochs=50, lr=0.001, min_lr=1e-05, reduce_lr_patience=5, reduce_lr_factor=0.1, early_stopping_p=20, mlflow_source='./mlruns', cutmix_p=0.0, cutmix_beta=0.0, usual_aug_with_cutmix=False, hair_aug_p=0.0, hair_rmv_p=0.0, random_rotate_p=0.5, p_horizontal_flip=0.5, p_vertical_flip=0.5, p_center_crop=0.5, mosaic_p=0.0, loss='dice_loss', label_smoothing=0, focal_loss_gamma=2, pos_weight=1, neg_weight=1, train_path='data/train', test_path='data/test', mask_train_path='data/mask_train', mask_test_path='data/mask_test', val_path='data/val', mask_val_path='data/mask_val', verbose=1, save_path='saved_models/', dataset_name='ISIC_2016', seed=1235, img_size=(256, 256), save_path_name='usual_1', model='unet_res50')\n",
      "[INFO] Successfully created MLFLOW-Handler\n",
      "2022-02-26 22:21:30,520 - SKIN-CANCER - INFO - Data Loader is successfully loaded!\n",
      "2022-02-26 22:21:30.529149: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-26 22:21:30.529317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.529424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.529476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.839260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.839375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.839435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-26 22:21:30.839487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21826 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Model: \"ResNet50_U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \r\n",
      "                                                                                                  \r\n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \r\n",
      " ization)                       )                                                                 \r\n",
      "                                                                                                  \r\n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \r\n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \r\n",
      "                                                                                                  \r\n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \r\n",
      "                                )                                                                 \r\n",
      "                                                                                                  \r\n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['conv4_block6_out[0][0]']       \r\n",
      " ose)                                                                                             \r\n",
      "                                                                                                  \r\n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \r\n",
      "                                )                                 'conv3_block4_out[0][0]']       \r\n",
      "                                                                                                  \r\n",
      " conv2d (Conv2D)                (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \r\n",
      "                                                                                                  \r\n",
      " batch_normalization (BatchNorm  (None, 32, 32, 512)  2048       ['conv2d[0][0]']                 \r\n",
      " alization)                                                                                       \r\n",
      "                                                                                                  \r\n",
      " activation (Activation)        (None, 32, 32, 512)  0           ['batch_normalization[0][0]']    \r\n",
      "                                                                                                  \r\n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation[0][0]']             \r\n",
      "                                                                                                  \r\n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_1[0][0]']               \r\n",
      " rmalization)                                                                                     \r\n",
      "                                                                                                  \r\n",
      " activation_1 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_1[0][0]']  \r\n",
      "                                                                                                  \r\n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['activation_1[0][0]']           \r\n",
      " spose)                                                                                           \r\n",
      "                                                                                                  \r\n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \r\n",
      "                                                                  'conv2_block3_out[0][0]']       \r\n",
      "                                                                                                  \r\n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \r\n",
      "                                                                                                  \r\n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_2[0][0]']               \r\n",
      " rmalization)                                                                                     \r\n",
      "                                                                                                  \r\n",
      " activation_2 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_2[0][0]']  \r\n",
      "                                                                                                  \r\n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_2[0][0]']           \r\n",
      "                                                                                                  \r\n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_3[0][0]']               \r\n",
      " rmalization)                                                                                     \r\n",
      "                                                                                                  \r\n",
      " activation_3 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_3[0][0]']  \r\n",
      "                                                                                                  \r\n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['activation_3[0][0]']           \r\n",
      " spose)                         8)                                                                \r\n",
      "                                                                                                  \r\n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 19  0           ['conv2d_transpose_2[0][0]',     \r\n",
      "                                2)                                'conv1_relu[0][0]']             \r\n",
      "                                                                                                  \r\n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 12  221312      ['concatenate_2[0][0]']          \r\n",
      "                                8)                                                                \r\n",
      "                                                                                                  \r\n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 12  512        ['conv2d_4[0][0]']               \r\n",
      " rmalization)                   8)                                                                \r\n",
      "                                                                                                  \r\n",
      " activation_4 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_4[0][0]']  \r\n",
      "                                8)                                                                \r\n",
      "                                                                                                  \r\n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 12  147584      ['activation_4[0][0]']           \r\n",
      "                                8)                                                                \r\n",
      "                                                                                                  \r\n",
      " batch_normalization_5 (BatchNo  (None, 128, 128, 12  512        ['conv2d_5[0][0]']               \r\n",
      " rmalization)                   8)                                                                \r\n",
      "                                                                                                  \r\n",
      " activation_5 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_5[0][0]']  \r\n",
      "                                8)                                                                \r\n",
      "                                                                                                  \r\n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['activation_5[0][0]']           \r\n",
      " spose)                         )                                                                 \r\n",
      "                                                                                                  \r\n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 67  0           ['conv2d_transpose_3[0][0]',     \r\n",
      "                                )                                 'input_1[0][0]']                \r\n",
      "                                                                                                  \r\n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 64  38656       ['concatenate_3[0][0]']          \r\n",
      "                                )                                                                 \r\n",
      "                                                                                                  \r\n",
      " batch_normalization_6 (BatchNo  (None, 256, 256, 64  256        ['conv2d_6[0][0]']               \r\n",
      " rmalization)                   )                                                                 \r\n",
      "                                                                                                  \r\n",
      " activation_6 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_6[0][0]']  \r\n",
      "                                )                                                                 \r\n",
      "                                                                                                  \r\n",
      " conv2d_7 (Conv2D)              (None, 256, 256, 64  36928       ['activation_6[0][0]']           \r\n",
      "                                )                                                                 \r\n",
      "                                                                                                  \r\n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 64  256        ['conv2d_7[0][0]']               \r\n",
      " rmalization)                   )                                                                 \r\n",
      "                                                                                                  \r\n",
      " activation_7 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_7[0][0]']  \r\n",
      "                                )                                                                 \r\n",
      "                                                                                                  \r\n",
      " conv2d_8 (Conv2D)              (None, 256, 256, 1)  65          ['activation_7[0][0]']           \r\n",
      "                                                                                                  \r\n",
      "==================================================================================================\r\n",
      "Total params: 20,676,545\r\n",
      "Trainable params: 20,642,113\r\n",
      "Non-trainable params: 34,432\r\n",
      "__________________________________________________________________________________________________\r\n",
      "2022-02-26 22:21:31,565 - SKIN-CANCER - INFO - model: unet_res50 is successfully loaded!\r\n",
      "2022-02-26 22:21:31.566152: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\r\n",
      "2022-02-26 22:21:31.566165: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\r\n",
      "2022-02-26 22:21:31.566811: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\r\n",
      "2022-02-26 22:21:31.566962: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ai/miniconda3/envs/tf-gpu/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-11.6/lib64\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-26 22:21:31.624082: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-02-26 22:21:31.624249: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "[INFO] Successfully created following callbacks [model_checkpoint, reduce_lr, early_stop, csv_logger, tensorboard]\n",
      "2022-02-26 22:21:31,627 - SKIN-CANCER - INFO - loss: dice_loss is successfully created!\n",
      "2022-02-26 22:21:31,631 - SKIN-CANCER - INFO - Start train for saved_models/ISIC_2016/unet_res50/usual_1/exp_2\n",
      "Epoch 1/50\n",
      "2022-02-26 22:21:34.446928: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8301\n",
      " 1/90 [..............................] - ETA: 7:18 - loss: 0.5796 - dice_score: 0.4204 - iou: 0.2661 - dice_loss: 0.5796 - jaccard_loss: 0.6187 - focal_tversky_loss: 0.68282022-02-26 22:21:36.764707: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-02-26 22:21:36.764729: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-02-26 22:21:37.353718: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2022-02-26 22:21:37.354085: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
      "2022-02-26 22:21:37.388091: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:521]  GpuTracer has collected 1686 callback api events and 1694 activity events. \n",
      "2022-02-26 22:21:37.401918: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "2022-02-26 22:21:37.419434: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37\n",
      "\n",
      "2022-02-26 22:21:37.433109: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37/ai.trace.json.gz\n",
      "2022-02-26 22:21:37.459341: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37\n",
      "\n",
      "2022-02-26 22:21:37.462671: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37/ai.memory_profile.json.gz\n",
      "2022-02-26 22:21:37.463778: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37\n",
      "Dumped tool data for xplane.pb to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37/ai.xplane.pb\n",
      "Dumped tool data for overview_page.pb to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37/ai.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37/ai.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37/ai.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/tensorboard_train/train/plugins/profile/2022_02_26_22_21_37/ai.kernel_stats.pb\n",
      "\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.2099 - dice_score: 0.7901 - iou: 0.6629 - dice_loss: 0.2099 - jaccard_loss: 0.2976 - focal_tversky_loss: 0.2946\n",
      "Epoch 00001: val_loss improved from inf to 0.54266, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "2022-02-26 22:22:07.227346: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "90/90 [==============================] - 39s 387ms/step - loss: 0.2099 - dice_score: 0.7901 - iou: 0.6629 - dice_loss: 0.2099 - jaccard_loss: 0.2976 - focal_tversky_loss: 0.2946 - val_loss: 0.5427 - val_dice_score: 0.4573 - val_iou: 0.3006 - val_dice_loss: 0.5427 - val_jaccard_loss: 0.6912 - val_focal_tversky_loss: 0.5250 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1632 - dice_score: 0.8368 - iou: 0.7234 - dice_loss: 0.1632 - jaccard_loss: 0.2645 - focal_tversky_loss: 0.2529\n",
      "Epoch 00002: val_loss did not improve from 0.54266\n",
      "90/90 [==============================] - 28s 308ms/step - loss: 0.1632 - dice_score: 0.8368 - iou: 0.7234 - dice_loss: 0.1632 - jaccard_loss: 0.2645 - focal_tversky_loss: 0.2529 - val_loss: 0.9789 - val_dice_score: 0.0211 - val_iou: 0.0107 - val_dice_loss: 0.9789 - val_jaccard_loss: 0.9891 - val_focal_tversky_loss: 0.9885 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1366 - dice_score: 0.8634 - iou: 0.7627 - dice_loss: 0.1366 - jaccard_loss: 0.2296 - focal_tversky_loss: 0.2243\n",
      "Epoch 00003: val_loss improved from 0.54266 to 0.44155, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "90/90 [==============================] - 34s 376ms/step - loss: 0.1366 - dice_score: 0.8634 - iou: 0.7627 - dice_loss: 0.1366 - jaccard_loss: 0.2296 - focal_tversky_loss: 0.2243 - val_loss: 0.4416 - val_dice_score: 0.5584 - val_iou: 0.3917 - val_dice_loss: 0.4416 - val_jaccard_loss: 0.6053 - val_focal_tversky_loss: 0.5705 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1254 - dice_score: 0.8746 - iou: 0.7795 - dice_loss: 0.1254 - jaccard_loss: 0.2143 - focal_tversky_loss: 0.2127\n",
      "Epoch 00004: val_loss did not improve from 0.44155\n",
      "90/90 [==============================] - 28s 311ms/step - loss: 0.1254 - dice_score: 0.8746 - iou: 0.7795 - dice_loss: 0.1254 - jaccard_loss: 0.2143 - focal_tversky_loss: 0.2127 - val_loss: 0.8421 - val_dice_score: 0.1579 - val_iou: 0.0863 - val_dice_loss: 0.8421 - val_jaccard_loss: 0.9129 - val_focal_tversky_loss: 0.9094 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1234 - dice_score: 0.8766 - iou: 0.7827 - dice_loss: 0.1234 - jaccard_loss: 0.2120 - focal_tversky_loss: 0.2106\n",
      "Epoch 00005: val_loss did not improve from 0.44155\n",
      "90/90 [==============================] - 28s 312ms/step - loss: 0.1234 - dice_score: 0.8766 - iou: 0.7827 - dice_loss: 0.1234 - jaccard_loss: 0.2120 - focal_tversky_loss: 0.2106 - val_loss: 0.4843 - val_dice_score: 0.5157 - val_iou: 0.3495 - val_dice_loss: 0.4843 - val_jaccard_loss: 0.6490 - val_focal_tversky_loss: 0.6226 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1285 - dice_score: 0.8715 - iou: 0.7761 - dice_loss: 0.1285 - jaccard_loss: 0.2193 - focal_tversky_loss: 0.2156\n",
      "Epoch 00006: val_loss did not improve from 0.44155\n",
      "90/90 [==============================] - 28s 308ms/step - loss: 0.1285 - dice_score: 0.8715 - iou: 0.7761 - dice_loss: 0.1285 - jaccard_loss: 0.2193 - focal_tversky_loss: 0.2156 - val_loss: 0.7671 - val_dice_score: 0.2329 - val_iou: 0.1339 - val_dice_loss: 0.7671 - val_jaccard_loss: 0.8614 - val_focal_tversky_loss: 0.8599 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1322 - dice_score: 0.8678 - iou: 0.7705 - dice_loss: 0.1322 - jaccard_loss: 0.2254 - focal_tversky_loss: 0.2191\n",
      "Epoch 00007: val_loss did not improve from 0.44155\n",
      "90/90 [==============================] - 27s 305ms/step - loss: 0.1322 - dice_score: 0.8678 - iou: 0.7705 - dice_loss: 0.1322 - jaccard_loss: 0.2254 - focal_tversky_loss: 0.2191 - val_loss: 0.9974 - val_dice_score: 0.0026 - val_iou: 0.0013 - val_dice_loss: 0.9974 - val_jaccard_loss: 0.9987 - val_focal_tversky_loss: 0.9986 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1280 - dice_score: 0.8720 - iou: 0.7776 - dice_loss: 0.1280 - jaccard_loss: 0.2184 - focal_tversky_loss: 0.2113\n",
      "Epoch 00008: val_loss did not improve from 0.44155\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 28s 309ms/step - loss: 0.1280 - dice_score: 0.8720 - iou: 0.7776 - dice_loss: 0.1280 - jaccard_loss: 0.2184 - focal_tversky_loss: 0.2113 - val_loss: 0.9396 - val_dice_score: 0.0604 - val_iou: 0.0318 - val_dice_loss: 0.9396 - val_jaccard_loss: 0.9682 - val_focal_tversky_loss: 0.9663 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1092 - dice_score: 0.8908 - iou: 0.8055 - dice_loss: 0.1092 - jaccard_loss: 0.1907 - focal_tversky_loss: 0.1921\n",
      "Epoch 00009: val_loss did not improve from 0.44155\n",
      "90/90 [==============================] - 27s 303ms/step - loss: 0.1092 - dice_score: 0.8908 - iou: 0.8055 - dice_loss: 0.1092 - jaccard_loss: 0.1907 - focal_tversky_loss: 0.1921 - val_loss: 0.4921 - val_dice_score: 0.5079 - val_iou: 0.3538 - val_dice_loss: 0.4921 - val_jaccard_loss: 0.6443 - val_focal_tversky_loss: 0.6462 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1068 - dice_score: 0.8932 - iou: 0.8098 - dice_loss: 0.1068 - jaccard_loss: 0.1864 - focal_tversky_loss: 0.1903\n",
      "Epoch 00010: val_loss improved from 0.44155 to 0.26114, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "90/90 [==============================] - 34s 374ms/step - loss: 0.1068 - dice_score: 0.8932 - iou: 0.8098 - dice_loss: 0.1068 - jaccard_loss: 0.1864 - focal_tversky_loss: 0.1903 - val_loss: 0.2611 - val_dice_score: 0.7389 - val_iou: 0.6014 - val_dice_loss: 0.2611 - val_jaccard_loss: 0.3955 - val_focal_tversky_loss: 0.4131 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0970 - dice_score: 0.9030 - iou: 0.8253 - dice_loss: 0.0970 - jaccard_loss: 0.1707 - focal_tversky_loss: 0.1746\n",
      "Epoch 00011: val_loss improved from 0.26114 to 0.13125, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "90/90 [==============================] - 33s 373ms/step - loss: 0.0970 - dice_score: 0.9030 - iou: 0.8253 - dice_loss: 0.0970 - jaccard_loss: 0.1707 - focal_tversky_loss: 0.1746 - val_loss: 0.1313 - val_dice_score: 0.8687 - val_iou: 0.7719 - val_dice_loss: 0.1313 - val_jaccard_loss: 0.2244 - val_focal_tversky_loss: 0.2497 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0957 - dice_score: 0.9043 - iou: 0.8279 - dice_loss: 0.0957 - jaccard_loss: 0.1682 - focal_tversky_loss: 0.1726\n",
      "Epoch 00012: val_loss improved from 0.13125 to 0.09909, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "90/90 [==============================] - 34s 376ms/step - loss: 0.0957 - dice_score: 0.9043 - iou: 0.8279 - dice_loss: 0.0957 - jaccard_loss: 0.1682 - focal_tversky_loss: 0.1726 - val_loss: 0.0991 - val_dice_score: 0.9009 - val_iou: 0.8213 - val_dice_loss: 0.0991 - val_jaccard_loss: 0.1746 - val_focal_tversky_loss: 0.1896 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0920 - dice_score: 0.9080 - iou: 0.8329 - dice_loss: 0.0920 - jaccard_loss: 0.1632 - focal_tversky_loss: 0.1713\n",
      "Epoch 00013: val_loss did not improve from 0.09909\n",
      "90/90 [==============================] - 27s 305ms/step - loss: 0.0920 - dice_score: 0.9080 - iou: 0.8329 - dice_loss: 0.0920 - jaccard_loss: 0.1632 - focal_tversky_loss: 0.1713 - val_loss: 0.0996 - val_dice_score: 0.9004 - val_iou: 0.8205 - val_dice_loss: 0.0996 - val_jaccard_loss: 0.1753 - val_focal_tversky_loss: 0.1864 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0882 - dice_score: 0.9118 - iou: 0.8390 - dice_loss: 0.0882 - jaccard_loss: 0.1569 - focal_tversky_loss: 0.1626\n",
      "Epoch 00014: val_loss did not improve from 0.09909\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0882 - dice_score: 0.9118 - iou: 0.8390 - dice_loss: 0.0882 - jaccard_loss: 0.1569 - focal_tversky_loss: 0.1626 - val_loss: 0.1033 - val_dice_score: 0.8967 - val_iou: 0.8148 - val_dice_loss: 0.1033 - val_jaccard_loss: 0.1807 - val_focal_tversky_loss: 0.1735 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0887 - dice_score: 0.9113 - iou: 0.8384 - dice_loss: 0.0887 - jaccard_loss: 0.1575 - focal_tversky_loss: 0.1631\n",
      "Epoch 00015: val_loss did not improve from 0.09909\n",
      "90/90 [==============================] - 27s 305ms/step - loss: 0.0887 - dice_score: 0.9113 - iou: 0.8384 - dice_loss: 0.0887 - jaccard_loss: 0.1575 - focal_tversky_loss: 0.1631 - val_loss: 0.1026 - val_dice_score: 0.8974 - val_iou: 0.8160 - val_dice_loss: 0.1026 - val_jaccard_loss: 0.1790 - val_focal_tversky_loss: 0.1700 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0822 - dice_score: 0.9178 - iou: 0.8491 - dice_loss: 0.0822 - jaccard_loss: 0.1468 - focal_tversky_loss: 0.1557\n",
      "Epoch 00016: val_loss did not improve from 0.09909\n",
      "90/90 [==============================] - 27s 302ms/step - loss: 0.0822 - dice_score: 0.9178 - iou: 0.8491 - dice_loss: 0.0822 - jaccard_loss: 0.1468 - focal_tversky_loss: 0.1557 - val_loss: 0.1247 - val_dice_score: 0.8753 - val_iou: 0.7831 - val_dice_loss: 0.1247 - val_jaccard_loss: 0.2128 - val_focal_tversky_loss: 0.1781 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0863 - dice_score: 0.9137 - iou: 0.8430 - dice_loss: 0.0863 - jaccard_loss: 0.1528 - focal_tversky_loss: 0.1591\n",
      "Epoch 00017: val_loss did not improve from 0.09909\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0863 - dice_score: 0.9137 - iou: 0.8430 - dice_loss: 0.0863 - jaccard_loss: 0.1528 - focal_tversky_loss: 0.1591 - val_loss: 0.1143 - val_dice_score: 0.8857 - val_iou: 0.7971 - val_dice_loss: 0.1143 - val_jaccard_loss: 0.1981 - val_focal_tversky_loss: 0.1667 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0845 - dice_score: 0.9155 - iou: 0.8453 - dice_loss: 0.0845 - jaccard_loss: 0.1504 - focal_tversky_loss: 0.1597\n",
      "Epoch 00018: val_loss did not improve from 0.09909\n",
      "90/90 [==============================] - 27s 304ms/step - loss: 0.0845 - dice_score: 0.9155 - iou: 0.8453 - dice_loss: 0.0845 - jaccard_loss: 0.1504 - focal_tversky_loss: 0.1597 - val_loss: 0.1058 - val_dice_score: 0.8942 - val_iou: 0.8150 - val_dice_loss: 0.1058 - val_jaccard_loss: 0.1793 - val_focal_tversky_loss: 0.1676 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0813 - dice_score: 0.9187 - iou: 0.8511 - dice_loss: 0.0813 - jaccard_loss: 0.1447 - focal_tversky_loss: 0.1528\n",
      "Epoch 00019: val_loss improved from 0.09909 to 0.09296, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "90/90 [==============================] - 34s 376ms/step - loss: 0.0813 - dice_score: 0.9187 - iou: 0.8511 - dice_loss: 0.0813 - jaccard_loss: 0.1447 - focal_tversky_loss: 0.1528 - val_loss: 0.0930 - val_dice_score: 0.9070 - val_iou: 0.8311 - val_dice_loss: 0.0930 - val_jaccard_loss: 0.1633 - val_focal_tversky_loss: 0.1606 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0785 - dice_score: 0.9215 - iou: 0.8557 - dice_loss: 0.0785 - jaccard_loss: 0.1402 - focal_tversky_loss: 0.1498\n",
      "Epoch 00020: val_loss improved from 0.09296 to 0.09278, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "90/90 [==============================] - 34s 382ms/step - loss: 0.0785 - dice_score: 0.9215 - iou: 0.8557 - dice_loss: 0.0785 - jaccard_loss: 0.1402 - focal_tversky_loss: 0.1498 - val_loss: 0.0928 - val_dice_score: 0.9072 - val_iou: 0.8314 - val_dice_loss: 0.0928 - val_jaccard_loss: 0.1632 - val_focal_tversky_loss: 0.1656 - lr: 1.0000e-05\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0788 - dice_score: 0.9212 - iou: 0.8549 - dice_loss: 0.0788 - jaccard_loss: 0.1408 - focal_tversky_loss: 0.1490\n",
      "Epoch 00021: val_loss improved from 0.09278 to 0.09270, saving model to saved_models/ISIC_2016/unet_res50/usual_1/exp_2/model\n",
      "90/90 [==============================] - 34s 376ms/step - loss: 0.0788 - dice_score: 0.9212 - iou: 0.8549 - dice_loss: 0.0788 - jaccard_loss: 0.1408 - focal_tversky_loss: 0.1490 - val_loss: 0.0927 - val_dice_score: 0.9073 - val_iou: 0.8328 - val_dice_loss: 0.0927 - val_jaccard_loss: 0.1619 - val_focal_tversky_loss: 0.1606 - lr: 1.0000e-05\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/90 [=========================>....] - ETA: 3s - loss: 0.0783 - dice_score: 0.9217 - iou: 0.8557 - dice_loss: 0.0783 - jaccard_loss: 0.1400 - focal_tversky_loss: 0.1487"
     ]
    }
   ],
   "source": [
    "!PYTHONHASHSEED=0\n",
    "!TF_DETERMINISTIC_OPS=0\n",
    "!TF_CUDNN_DETERMINISTIC=0\n",
    "for n in range(multi_train):\n",
    "    seed = seeds + n\n",
    "    saved_path_name = f\"{train_identifier}_{n}\"\n",
    "    !python train.py \\\n",
    "    --model $model --dataset_name $dataset_name \\\n",
    "    --save_path $save_path \\\n",
    "    --save_path_name $saved_path_name \\\n",
    "    --epochs $epochs \\\n",
    "    --optimizer $optimizer \\\n",
    "    --lr $lr \\\n",
    "    --min_lr $min_lr \\\n",
    "    --reduce_lr_patience $reduce_lr_patience \\\n",
    "    --reduce_lr_factor $reduce_lr_factor \\\n",
    "    --early_stopping_p $early_stopping_p \\\n",
    "    --hair_aug_p $hair_aug_p \\\n",
    "    --hair_rmv_p $hair_rmv_p \\\n",
    "    --random_rotate_p $random_rotate_p \\\n",
    "    --p_horizontal_flip $p_horizontal_flip \\\n",
    "    --p_vertical_flip $p_vertical_flip \\\n",
    "    --p_center_crop $p_center_crop \\\n",
    "    --mosaic_p $mosaic_p \\\n",
    "    --cutmix_p $cutmix_p \\\n",
    "    --cutmix_beta $cutmix_beta \\\n",
    "    --seed $seed\n",
    "    \n",
    "    print(f\"\\n-----------------------------train {n} is done! ----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977a1b7",
   "metadata": {
    "id": "0977a1b7"
   },
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34cf3098",
   "metadata": {
    "id": "34cf3098",
    "outputId": "d581a2c5-f802-4e46-ebdb-8f9220da1b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting values from csv files...\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/0/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/1/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/2/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/3/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/4/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/5/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/6/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/7/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/8/log.csv\n",
      "[INFO] Getting the values of file ./checkpoints/WaveletCustom/9/log.csv\n",
      "{'accuracy': {'std': 0.0, 'mean': 1.0}, 'loss': {'std': 0.0001, 'mean': 0.0001}, 'val_accuracy': {'std': 0.032, 'mean': 0.962}, 'val_loss': {'std': 0.1254, 'mean': 0.2029}}\n"
     ]
    }
   ],
   "source": [
    "from utils.group_metrics import get_mean_std\n",
    "import os\n",
    "\n",
    "csv_addresses = [\n",
    " os.path.join(save_path, dataset_name, model, f\"{train_identifier}_{n}\", \"exp_2\" , \"csv_logger_train.csv\") for n in range(multi_train)   \n",
    "]\n",
    "metrics = get_mean_std(csv_addresses, \n",
    "                       arguments=(\n",
    "                           \"dice_loss\",\n",
    "                           \"dice_score\",\n",
    "                           \"focal_tversky_loss\",\n",
    "                           \"iou\",\n",
    "                           \"jaccard_loss\",\n",
    "                           \"loss\",\n",
    "                           \"val_dice_loss\",\n",
    "                           \"val_dice_score\",\n",
    "                           \"val_focal_tversky_loss\",\n",
    "                           \"val_iou\",\n",
    "                           \"val_jaccard_loss\",\n",
    "                           \"val_loss\"\n",
    "                       ),\n",
    "                       operators=(min, max, min, max, min, min, min, max, min, max, min, min)\n",
    "                      )\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49feee3c",
   "metadata": {},
   "source": [
    "_:)_"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
